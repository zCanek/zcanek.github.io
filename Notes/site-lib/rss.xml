<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Anom]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>site-lib/media/favicon.png</url><title>Anom</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Wed, 28 Jan 2026 21:15:19 GMT</lastBuildDate><atom:link href="site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Wed, 28 Jan 2026 21:15:08 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[CBC - Cyber-Block Chaining]]></title><description><![CDATA[This is what ensures that no two blocks (even if they contain identical plaintext) will encrypt to the same ciphertext. It does this by mixing the ciphertext from the previous round into the plaintext of the next round using the XOR operator. In mathematical notation:
Let = the plaintext, and = the plaintext of block .
Let = the corresponding ciphertext, and = the ciphertext of block .
Let = the number of blocks ( and have the same number of blocks by definition).
Let = the initialization vector - a random string - frequently (incorrectly) set to all zeroes.
Let = a single-block encryption operation (any block encryption algorithm, such as AES or DES, it doesn't matter which), with some unique and unknown (to the attacker) secret key (that we don't notate here).
Let = the corresponding decryption operation.
We can define the encrypted ciphertexct -- in terms of the encryption algorithm, the plaintext, and the initialization vector:<img alt="Pasted image 20260128110417.png" src="assets/pasted-image-20260128110417.png" target="_self">Decryption is the opposite:<br><img alt="Pasted image 20260128110814.png" src="assets/pasted-image-20260128110814.png" target="_self"><br>
Once all blocks are decrypted, the <a data-href="Padding" href="indexes/cryptography/padding.html" class="internal-link" target="_self" rel="noopener nofollow">Padding</a> on the last block is validated.]]></description><link>indexes/cryptography/cbc-cyber-block-chaining.html</link><guid isPermaLink="false">Indexes/Cryptography/CBC - Cyber-Block Chaining.md</guid><pubDate>Wed, 28 Jan 2026 17:17:31 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.3.1 Unsigned Addition]]></title><description><![CDATA[Consider two nonnegative integers x and y, such that 0 ≤ x, y &lt; 2w. Each of these values can be represented by a w-bit unsigned number. If we compute their sum, however, we have a possible range 0 ≤ x + y ≤ 2w+1 − 2. Representing this sum could require w + 1 bits.Figure 2.21 shows a plot of the function x + y when x and y have 4-bit representations. The arguments (shown on the horizontal axes) range from 0 to 15, but the sum ranges from 0 to 30. The shape of the function is a sloping plane (the function is linear in both dimensions). If we were to maintain the sum as a (w + 1)-bit number and add it to another value, we may require w + 2 bits, and so on.
<img alt="Pasted image 20250807171802.png" src="assets/pasted-image-20250807171802.png" target="_self">
This continued "word size inflation" means we cannot place any bound on the word size required to fully represent the results of arithmetic operations.Let us define the operation for arguments and , where , as the result of truncating the integer sum to be bits long and then viewing the result as an unsigned number.
This can be characterized as a form of modular arithmetic, computing the sum modulo by simply discarding any bits with weight greater than in the bit-level representation of . For example, consider a -bit number representation with and , having bit representations and , respectively. Their sum is 21, having a 5-bit representation . But if we discard the high-order bit, we get [0101], that is, decimal value 5. This matches the value 21 mod 16 = 5.So we can characterize operation as follows:Unsigned addition
For and such that : -^u_w x =
\begin{cases}
x, &amp; x = 0 \quad \
2^w − x, &amp; x &gt; 0 \quad
\end{cases}]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.3-integer-arithmetic/2.3.1-unsigned-addition.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.3 Integer Arithmetic/2.3.1 Unsigned Addition.md</guid><pubDate>Wed, 28 Jan 2026 01:45:16 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.1.8 Logical Operations in C]]></title><description><![CDATA[Operators ||, &amp;&amp;, and ! treat any nonzero argument as representing TRUE and argument 0 FALSE. They return either 1 or 0 (true or false).
<img alt="Pasted image 20250724134626.png" src="assets/pasted-image-20250724134626.png" target="_self"><br>
An important distinction between the logical operators ‘&amp;&amp;’ and ‘||’ versus their <a data-tooltip-position="top" aria-label="2.1.7 Bitwise operators" data-href="2.1.7 Bitwise operators" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.7-bitwise-operators.html" class="internal-link" target="_self" rel="noopener nofollow">bit-level</a> counterparts ‘&amp;’ and ‘|’ is that the logical operators do not evaluate their second argument if the result of the expression can be determined by evaluating the first argument. Thus, for example, the expression a &amp;&amp; 5/a will never cause a division by zero, and the expression p &amp;&amp; *p++ will never cause the dereferencing of a null <a data-tooltip-position="top" aria-label="Pointers" data-href="Pointers" href="indexes/coding/c/pointers.html" class="internal-link" target="_self" rel="noopener nofollow">pointer</a>.]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.8-logical-operations-in-c.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.8 Logical Operations in C.md</guid><pubDate>Tue, 27 Jan 2026 23:58:27 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.3.2 Two's-Complement Addition]]></title><description><![CDATA[With two’s-complement addition, we must decide what to do when the result is either too large (positive) or too small (negative) to represent. Given integer values and in the range , their sum is in the range , potentially requiring bits to represent exactly.Let us define to be the result of truncating the integer sum to be bits long and then viewing the result as a two’s-complement number.Two's-complement addition
For integer values and in the range : This principle is illustrated in Figure 2.24, where the sum is shown on the left, having a value in the range , and the result of truncating the sum to a -bit two’s-complement number is shown on the right. (The labels “Case 1” to “Case 4” in this figure are for the case analysis of the formal derivation of the principle.) When the sum exceeds (case 4), we say that positive overflow has occurred. In this case, the effect of truncation is to subtract from the sum. When the sum is less than (case 1), we say that negative overflow has occurred. In this case, the effect of truncation is to add to the sum.
The -bit two’s-complement sum of two numbers has the exact same bit-level
representation as the unsigned sum. In fact, most computers use the same machine instruction to perform either unsigned or signed addition.
<img alt="Pasted image 20250807193243.png" src="assets/pasted-image-20250807193243.png" target="_self"><br>
<img alt="Pasted image 20250807193302.png" src="assets/pasted-image-20250807193302.png" target="_self">
Figure 2.26 illustrates two’s-complement addition for word size . The operands range between . When , two’s-complement addition has a negative overflow, causing the sum to be incremented by 16. When , the addition yields . When , the addition has a positive overflow, causing the sum to be decremented by . Each of these three ranges forms a sloping plane in the figure.<br>
<img alt="Pasted image 20250807193731.png" src="assets/pasted-image-20250807193731.png" target="_self">Detecting overflow in two's-complement addition
For and in the range , let . Then the computation of has had positive overflow if and only if and but . The computation has had negative overflow if and only if and but .
]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.3-integer-arithmetic/2.3.2-two's-complement-addition.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.3 Integer Arithmetic/2.3.2 Two's-Complement Addition.md</guid><pubDate>Mon, 18 Aug 2025 17:59:13 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.1.3 Addressing and Byte Ordering]]></title><description><![CDATA[For program objects that span multiple bytes, we must establish two conventions: what the address of the object will be, and how we will order the bytes in memory. In virtually all machines, a multi-byte object is stored as a contiguous sequence of bytes, with the address of the object given by the smallest address of the bytes used. For example, suppose a variable x of type int has address 0x100; that is, the value of the address expression &amp;x is 0x100. Then (assuming <a data-tooltip-position="top" aria-label="Data Types" data-href="Data Types" href="indexes/coding/c井/data-types.html" class="internal-link" target="_self" rel="noopener nofollow">data type</a> int has a 32-bit representation) the 4 bytes of x would be stored in memory locations 0x100, 0x101, 0x102, and 0x103.For ordering the bytes representing an object, there are two common conventions. Consider a -bit integer having a bit representation , where is the most significant bit and is the least. Assuming w is a multiple of 8, these bits can be grouped as bytes, with the most significant byte having bits , the least significant byte having bits , and the other bytes having bits from the middle. Some machines choose to store the object in memory ordered from least significant byte to most, while other machines store them from most to least. The former convention—where the least significant byte comes first—is referred to as little endian. The latter convention—*where the most significant byte comes first—is referred to as big endian.<br>Suppose the variable x of type int and at address 0x100 has a <a data-tooltip-position="top" aria-label="2.1.1 Hexadecimal Notation" data-href="2.1.1 Hexadecimal Notation" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.1-hexadecimal-notation.html" class="internal-link" target="_self" rel="noopener nofollow">hexadecimal</a> value of 0x01234567. The ordering of the bytes within the address range 0x100 through 0x103 depends on the type of machine:<br>
<img alt="Pasted image 20250716204848.png" src="assets/pasted-image-20250716204848.png" target="_self">
Note that in the word 0x01234567 the high-order byte has a hexadecimal value 0x01, while the low-order byte has value 0x67.For most application programmers, the byte orderings used by their machines are totally invisible; programs compiled for either class of machine give identical results.
Most Intel-compatible machines operate exclusively in little-endian mode. On the other hand, most machines from IBM and Oracle operate in big-endian mode.
Many recent microprocessor chips are bi-endian, meaning that they can be configured to operate as either liitle or big endian machines The first is when binary data are communicated over a network between different machines. A common problem is for data produced by a little-endian machine to be sent to a big-endian machine, or vice versa, leading to the bytes within the words being in reverse order for the receiving program. To avoid such problems, code written for networking applications must follow established conventions for byte ordering to make sure the sending machine converts its internal representation to the network standard, while the receiving machine converts the network standard to its internal representation.
A second case where byte ordering becomes important is when looking at the byte sequences representing integer data. This occurs often when inspecting machine-level programs. As an example, the following line occurs in a file that gives a text representation of the machine-level code for an Intel x86-64 processor: 4004d3: 01 05 43 0b 20 00 add %eax,0x200b43(%rip) This line was generated by a disassembler, a tool that determines the instruction sequence represented by an executable program file.
We simply note that this line states that the hexadecimal byte sequence 01 05 43 0b 20 00 is the byte-level representation of an instruction that adds a word of data to the value stored at an address computed by adding 0x200b43 to the current value of the program counter, the address of the next instruction to be executed. If we take the final 4 bytes of the sequence 43 0b 20 00 and write them in reverse order, we have 00 20 0b 43. Dropping the leading 0, we have the value 0x200b43, the numeric value written on the right. Having bytes appear in reverse order is a common occurrence when reading machine-level program representations generated for little-endian machines such as this one. The natural way to write a byte sequence is to have the lowest-numbered byte on the left and the highest on the right, but this is contrary to the normal way of writing numbers with the most significant digit on the left and the least on the right.
A third case where byte ordering becomes visible is when programs are written that circumvent the normal type system. In the C language, this can be done using a cast or a union to allow an object to be referenced according to a different data type from which it was created. Such coding tricks are strongly discouraged for most application programming, but they can be quite useful and even necessary for system-level programming.
#include &lt;stdio.h&gt; typedef unsigned char *byte_pointer; void show_bytes(byte_pointer start, size_t len) { int i; for (i = 0; i &lt; len; i++) printf(" %.2x", start[i]); printf("\n");
} void show_int(int x) { show_bytes((byte_pointer) &amp;x, sizeof(int)); } void show_float(float x) { show_bytes((byte_pointer) &amp;x, sizeof(float));
} void show_pointer(void *x) {
show_bytes((byte_pointer) &amp;x, sizeof(void *));
}
//CODE TO PRINT THE BYTE REPRESENTATION OF PROGRAM OBJECTS
These procedures use the C sizeof operator to determine the number of bytes used by the object. In general, the expression sizeof(T ) returns the number of bytes required to store an object of type T.Using sizeof rather than a fixed value is one step toward writing code that is portable across different machine types.void test_show_bytes(int val)
{ int ival = val; float fval = (float) ival; int *pval = &amp;ival; show_int(ival); show_float(fval); show_pointer(pval);
}
//THIS CODE PRINTS THE BYTE REPRESENTATION OF SAMPLE DATA OBJECTS
<br><img alt="Pasted image 20250717130734.png" src="assets/pasted-image-20250717130734.png" target="_self" style="width: 600px; max-width: 100%;"><br>
Our argument 12,345 has <a data-tooltip-position="top" aria-label="2.1.1 Hexadecimal Notation" data-href="2.1.1 Hexadecimal Notation" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.1-hexadecimal-notation.html" class="internal-link" target="_self" rel="noopener nofollow">hexadecimal</a> representation (in big-endian). We can see that the leas significant byte value of is printed first for Linux 32, Windows and Linux 64, indicating little-endian machines, and last for Sun, indicating big-endian.
Note that the Linux 32, Windows and Sun machines use 4-byte addresses, while the Linux 64 uses 8-byte addresses.Although the floating-point and the int data both encode the numeric value 12,345, they have different patterns: for the integer and for floating point. In general, these two formats use different encoding schemes. If we expand these hexadecimal patterns into binary form and shift them appropriately, we find a sequence of 13 matching bits, indicated by a sequence of asterisks, as follows:<br>
<img alt="Pasted image 20250717141129.png" src="assets/pasted-image-20250717141129.png" target="_self">]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.3-addressing-and-byte-ordering.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.3 Addressing and Byte Ordering.md</guid><pubDate>Sun, 10 Aug 2025 23:40:49 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.3.7 Dividing by Powers of 2]]></title><description><![CDATA[Integer divisions in most machines is even slowe than multiplication, requiring 30 or more clock cycles,Dividing by a power of 2 can also be using <a data-tooltip-position="top" aria-label="2.1.9 Shift Operations in C" data-href="2.1.9 Shift Operations in C" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.9-shift-operations-in-c.html" class="internal-link" target="_self" rel="noopener nofollow">shift operations</a>, but we use a right shift rather than a left shift. The two different right shifts—<a data-tooltip-position="top" aria-label="2.1.9 Shift Operations in C" data-href="2.1.9 Shift Operations in C" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.9-shift-operations-in-c.html" class="internal-link" target="_self" rel="noopener nofollow">logical and arithmetic</a>—serve this purpose for unsigned and two’s-complement numbers, respectively. Integer division always rounds toward zero. To define this precisely, let us introduce some notation
For any real number , define to be the unique integer such that .
As examples, , , and . Similarly, define to be the unique integer such that . As examples, , , and . For and , integer division should yield , while for and , it should yield . That is, it should round down a positive result but round up a negative one.
The case for using shifts with unsigned arithmetic is straightforward, in part because
right shifting is guaranteed to be performed logically for unsigned values.Unsigned division by a power of 2
For C variables and with unsigned values and , such that , the C expression yields the value <br><img alt="Pasted image 20250808193539.png" src="assets/pasted-image-20250808193539.png" target="_self">
Figure 2.28 shows the effects of performing logical right shifts on a 16-bit representation of 12,340 to perform division by 1, 2, 16, and 256. The zeros shifted in from the left are shown in italics. We also show the result we would obtain if we did these divisions with real arithmetic. These examples show that the result of shifting consistently rounds toward zero, as is the convention for integer division<br>
<img alt="Pasted image 20250808193628.png" src="assets/pasted-image-20250808193628.png" target="_self">
The case for dividing by a power of 2 with two’s-complement arithmetic is slightly more complex. First, the shifting should be performed using an arithmetic right shift, to ensure that negative values remain negative. Let us investigate what value such a right shift would produce.Two's-complement division by a power of 2, rounding down
Let C variables and have two’s-complement value and unsigned value , respectively, such that . The C expression , when the shift is performed arithmetically, yields the value For , variable has as the most significant bit, and so the effect of an arithmetic shift is the same as for a logical right shift. Thus, an arithmetic right shift by is the same as division by for a nonnegative number. As an example of a negative number, Figure 2.29 shows the effect of applying arithmetic right shift to a -bit representation of for different shift amounts. For the case when no rounding is required , the result will be . When rounding is required, shifting causes the result to be rounded downward. For example, the shifting right by four has the effect of rounding down to . We will need to adjust our strategy to handle division for negative values of .<br>
<img alt="Pasted image 20250808194016.png" src="assets/pasted-image-20250808194016.png" target="_self">
We can correct for the improper rounding that occurs when a negative number is shifted right by “biasing” the value before shifting.Two's-complement division by a power of 2, rounding up
...
... Continue...]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.3-integer-arithmetic/2.3.7-dividing-by-powers-of-2.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.3 Integer Arithmetic/2.3.7 Dividing by Powers of 2.md</guid><pubDate>Sat, 09 Aug 2025 03:17:04 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.3.6 Multiplying by Constants]]></title><description><![CDATA[Integer multiply instruction on many machines is slower than other operations. Even on the Inter Core i7 Haswell we use as our reference machine, integer multiply requires 3 clock cycles. So, one important optimization used by compiler is to attempt to replace multiplications by constant factors with combinations of shift and addition operations. We will first consider the case of multiplying by a power of 2, and then we will generalize this to arbitrary constants.Multiplication by a power of 2
Let be the unsigned integer represented by bit pattern . Then for any , the -bit unsigned representation of is given by , where zeros have been added to the right.
So, for example, 11 can be represented for as . Shifting this left by yields the 6-bit vector, which encodes the unsigned number .When shifting left by for a fixed word size, the high-order bits are discarded, yieldingbut this is also the case when performing multiplication on fixed-size words. We can therefore see that shifting a value left is equivalent to performing unsigned multiplication by a power of 2:Unsigned multiplication by a power of 2
For C variables and with unsigned values and , such that , the C expression yields the value .
Since the bit-level operation of fixed-size two’s-complement arithmetic is equivalent to that for unsigned arithmetic, we can make a similar statement about the relationship between left shifts and multiplication by a power of 2 for two’s-complement arithmetic:Two's-complement multiplication by a power of 2
For C variables and with two's-complement value and unsigned value , such that , the C expression yields the value .
Note that multiplying by a power of 2 can cause overflow with either unsigned or two’s-complement arithmetic. Our result shows that even then we will get the same effect by shifting. Returning to our earlier example, we shifted the -bit pattern (numeric value ) left by two positions to get (numeric value ). Truncating this to bits gives (numeric value ).Given that integer multiplication is more costly than shifting and adding, many C compilers try to remove many cases where an integer is being multiplied by a constant with combinations of shifting, adding, and subtracting. For example, suppose a program contains the expression . Recognizing that , the compiler can rewrite the multiplication as , replacing one multiplication with three shifts and two additions. The two computations will yield the same result, regardless of whether is unsigned or two’s complement, and even if the multiplication would cause an overflow. Even better, the compiler can also use the property to rewrite the multiplication as , requiring only two shifts and a subtractionGeneralizing from our example, consider the task of generating code for the expression , for some constant . The compiler can express the binary representation of $K as an alternating sequence of zeros and ones: By adding together the results for each run, we are able to compute x * K without any multiplications. Of course, the trade-off between using combinations of shifting, adding, and subtracting versus a single multiplication instruction depends on the relative speeds of these instructions, and these can be highly machine dependent. Most compilers only perform this optimization when a small number of shifts, adds, and subtractions suffice.]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.3-integer-arithmetic/2.3.6-multiplying-by-constants.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.3 Integer Arithmetic/2.3.6 Multiplying by Constants.md</guid><pubDate>Sat, 09 Aug 2025 01:18:10 GMT</pubDate></item><item><title><![CDATA[2.3.5 Two's-complement multiplication]]></title><description><![CDATA[Integers and in the range can be represented as -bit two’s-complement numbers, but their product can range between and . This could require as many as bits to represent in two’s-complement form. Instead, signed multiplication in C generally is performed by truncating the -bit product to bits. We denote this value as . Truncating a two’s-complement number to w bits is equivalent to first computing its value modulo and then converting from unsigned to two’s complement, giving the following:Two's-complement multiplication
For and such that : The bit-level representation of the product operation is identical for both unsigned and two’s-complement multiplication.
<img alt="Pasted image 20250808164737.png" src="assets/pasted-image-20250808164737.png" target="_self">]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.3-integer-arithmetic/2.3.5-two's-complement-multiplication.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.3 Integer Arithmetic/2.3.5 Two's-complement multiplication.md</guid><pubDate>Fri, 08 Aug 2025 22:47:37 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.3.4 Unsigned Multiplication]]></title><description><![CDATA[Integers and in the range can be represented as -bit unsigned numbers, but their product can range between and . This could require as many as bits to represent. Instead, unsigned multiplication in C is defined to yield the -bit value given by the low-order bits of the -bit integer product. Let us denote this value as . Truncating an unsigned number to bits is equivalent to computing its value modulo , giving the following:Unsigned multiplication
For and such that : ]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.3-integer-arithmetic/2.3.4-unsigned-multiplication.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.3 Integer Arithmetic/2.3.4 Unsigned Multiplication.md</guid><pubDate>Fri, 08 Aug 2025 02:52:02 GMT</pubDate></item><item><title><![CDATA[2.3.3 Two's Complement Negation]]></title><description><![CDATA[We can see that every number in the range has an additive inverse under , which we denote as follows:Two's-complement negation
For in the range , its two’s-complement negation is given by the formula That is, for -bit two's-complement addition, is its own additive inverse, while any other value has as its additive inverse.
]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.3-integer-arithmetic/2.3.3-two's-complement-negation.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.3 Integer Arithmetic/2.3.3 Two's Complement Negation.md</guid><pubDate>Fri, 08 Aug 2025 02:37:23 GMT</pubDate></item><item><title><![CDATA[2.2.8 Advice on Signed versus Unsigned]]></title><description><![CDATA[So implicit casting of signed to unsigned leads to some non-intuitive behavior. Nonintuitive features often lead to program bugs, and ones involving the nuances of implicit casting can be especially difficult to see. Since the casting takes place without any clear indication in the code, programmer often overlook its effects.We have seen multiple ways in which the subtle features of unsigned arithmetic, and especially the implicit conversion of signed to unsigned, can lead to errors or vulnerabilities. One way to avoid such bugs is to never use unsigned numbers.Unsigned values are very useful when we want to think of words as just collections of bits with no numeric interpretation. This occurs, for example, when packing a word with flags describing various Boolean conditions. Addresses are naturally unsigned, so systems programmers find unsigned types to be helpful. Unsigned values are also useful when implementing mathematical packages for modular arithmetic and for multiprecision arithmetic, in which numbers are represented by arrays of words.]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.8-advice-on-signed-versus-unsigned.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.8 Advice on Signed versus Unsigned.md</guid><pubDate>Wed, 06 Aug 2025 20:41:32 GMT</pubDate></item><item><title><![CDATA[2.2.7 Truncating Numbers]]></title><description><![CDATA[Suppose that, rather than extending a value with extra bits, we reduce the number of bits representing a number. This occurs in this codeint x = 53191;
short sx = (short) x; /* -12345 */
int y = sx; /* -12345 */
Casting x to be short will truncate a 32-bit int to a 16-bit short. As we saw before, this 16-bit pattern is the two’s-complement representation of −12,345. When casting this back to int, sign extension will set the high-order 16 bits to ones, yielding the 32-bit two’s-complement representation of −12,345.When truncating a -bit number to a -bit number, we drop the high-order bits, giving a bit vector . Truncating a number can alter its value—a form of overflow. For an unsigned number, we can readily characterize the numeric value that will result.Truncation of an unsigned number
Let be the bit vector , and let be the result of truncating it to bits: . Let and . Then mod .
The intuition behind this principle is simply that all of the bits that were truncated have weights of the form , where , and therefore each of these weights reduces to zero under the modulus operation. A similar property holds for truncating a two’s-complement number, except that it then converts the most significant bit into a sign bit:Truncation of a two's-complement number
Let be the bit vector , and let be the result of truncating it to bits: . Let and . Then mod .
In this formulation, mod will be a number between and . Applying function to it will have the effect of converting the most significant bit from having weight to having weight . We can see this with the example of converting value from int to short. Since , we have mod . But when we convert this number to a 16-bit two’s-complement number, we get .]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.7-truncating-numbers.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.7 Truncating Numbers.md</guid><pubDate>Wed, 06 Aug 2025 19:48:38 GMT</pubDate></item><item><title><![CDATA[2.2.6 Expanding the Bit representation of a Number]]></title><description><![CDATA[One common operation is to convert between integers having different word sizes while retaining the same numeric value. Of course, this may not be possible when the destination data type is too small to represent the desired value. Converting from a smaller to a larger data type, however, should always be possible.To convert an unsigned number to a larger data type, we can simply add leading zeros to the representation; this operation is known as zero extension, expressed by the following principle:Expansion of an unsigned number by zero extension
Define bit vectors of widh and of width , where . Then .
For converting a two's-complement number to a larger data type, the rule is to perform a sign extension, assign copies of the most significant bit to the representation, expressed by the following principle. We show the sign bit in bold to highlight its role in sign extension.Expansion of a two's-complement number by sign extension
Define bit vectors of widh and of width , where . Then .
<img alt="Pasted image 20250806124238.png" src="assets/pasted-image-20250806124238.png" target="_self">]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.6-expanding-the-bit-representation-of-a-number.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.6 Expanding the Bit representation of a Number.md</guid><pubDate>Wed, 06 Aug 2025 18:42:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.2.5 Signed versus Unsigned in C]]></title><description><![CDATA[Almost all machines use two’s complement. Generally, most numbers are signed by default. For example, when declaring a constant such as 12345 or 0x1A2B, the value is considered signed. Adding character ‘U’ or ‘u’ as a suffix creates an unsigned constant; for example, 12345U or 0x1A2Bu.C allows conversion between unsigned and signed most systems apply the function <a data-tooltip-position="top" aria-label="2.2.4 T2U &amp; U2T" data-href="2.2.4 T2U &amp; U2T" href="cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.4-t2u-&amp;-u2t.html" class="internal-link" target="_self" rel="noopener nofollow">U2T</a> when converting from unsigned to signed, and <a data-tooltip-position="top" aria-label="2.2.4 T2U &amp; U2T" data-href="2.2.4 T2U &amp; U2T" href="cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.4-t2u-&amp;-u2t.html" class="internal-link" target="_self" rel="noopener nofollow">T2U</a> when converting from signed to unsigned, where is the number of bits for the data type.Some possibly nonintuitive behavior arises due to C’s handling of expressions containing combinations of signed and unsigned quantities. When an operation is performed where one operand is signed and the other is unsigned, C implicitly casts the signed argument to unsigned and performs the operations assuming the numbers are nonnegative.<br>
<img alt="Pasted image 20250805221658.png" src="assets/pasted-image-20250805221658.png" target="_self">]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.5-signed-versus-unsigned-in-c.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.5 Signed versus Unsigned in C.md</guid><pubDate>Wed, 06 Aug 2025 04:44:13 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.2.4 T2U & U2T]]></title><description><![CDATA[C allows casting between different numeric data types. For example, suppose variable x is declared as int and u as unsigned. The expression (unsigned) x converts the value of x to an unsigned value, and (int) u converts the value of u to a signed integer. In casting from unsigned to int, the underlying bit representation stays the same, the numeric values might change, but the bit patterns do not.Conversion from two's complement to unsigned
For such that : For example, we saw that , and also that .
<img alt="Pasted image 20250805215808.png" src="assets/pasted-image-20250805215808.png" target="_self">
Figure 2.17 illustrates the general behavior of function . As it shows, when mapping a signed number to its unsigned counterpart, negative numbers are converted to large positive numbers, while nonnegative numbers remain unchanged.
Going in the other direction, we can state the relationship between an unsigned number u and its signed counterpart U2Tw (u):Unsigned to two's-complement conversion
For such that : <br><img alt="Pasted image 20250805220347.png" src="assets/pasted-image-20250805220347.png" target="_self">]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.4-t2u-&amp;-u2t.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.4 T2U &amp; U2T.md</guid><pubDate>Wed, 06 Aug 2025 04:03:53 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.2.3 Two's-Complement Encodings]]></title><description><![CDATA[The most common computer representation of signed numbers is known as two's-complement form. This is defined by interpreting the most significant bit of the word to have negative weight. We name this as a function (for "binary to two's complement" length )Definition of two's-complement encoding
For vector The most significant bit is also called the sign bit. Its "weight" is , the negation of its weight in an unsigned representation. When the sign bit is set to 1, the represented value is negative, and when set to 0, the value is nonnegative. <img alt="Pasted image 20250805133858.png" src="assets/pasted-image-20250805133858.png" target="_self">
Let us consider the range of values that can be represented as a w-bit two’scomplement number. The least representable value is given by bit vector (set the bit with negative weight but clear all others), having integer value . The greatest value is given by bit vector (clear the bit with negative weight but set all others), having integer value . Using the 4-bit case as an example, we have and .Uniqueness of two's-complement encoding
Function is a bijection
We define function (for “two’s complement to binary”) to be the inverse of . That is, for a number , such that , is the (unique) -bit pattern that encodes .The two’s-complement range is asymmetric: ; that is, there is no positive counterpart to . As we shall see, this leads to some peculiar properties of two’s-complement arithmetic and can be the source of subtle program bugs.<br>
<img alt="Pasted image 20250805140636.png" src="assets/pasted-image-20250805140636.png" target="_self"><br>
<img alt="Pasted image 20250805143818.png" src="assets/pasted-image-20250805143818.png" target="_self">There are two other standard representations for signed numbers: Ones’ complement. This is the same as two’s complement, except that the most significant bit has weight rather than : Sign magnitude. The most significant bit is a sign bit that determines whether the remaining bits should be given negative or positive weight: ]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.3-two's-complement-encodings.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.3 Two's-Complement Encodings.md</guid><pubDate>Tue, 05 Aug 2025 20:38:21 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.2.2 Unsigned Encodings]]></title><description><![CDATA[Let us consider an integer <a data-tooltip-position="top" aria-label="Data Types" data-href="Data Types" href="indexes/coding/c井/data-types.html" class="internal-link" target="_self" rel="noopener nofollow">data type</a> of bits. We write a bit vector as either , to denote the entire vector, or as to denote the individual bits within the vector. Treating as a number written in binary notation, we obtain the unsigned interpretation of . In this encoding, each bit has value 0 or 1, with the latter case indicating that value should be included as part of the numeric value. We can express this interpretation as a function (for “binary to unsigned,” length ):<br>
<img alt="Pasted image 20250725183303.png" src="assets/pasted-image-20250725183303.png" target="_self">
In this, we represent each bit position by a rightward-pointing blue bar of length . The numeric value associated with a bit vector then equals the sum of the lengths of the bars for which the corresponding bit values are 1.Definition of unsigned encoding
For vector In this equation, the notation means that the left-hand side is defined to be equal to the right-hand side. The function maps strings of zeros and ones of length to nonnegative integers. Let us consider the range of values that can be represented using bits. The least value is given by bit vector having integer value . Using the 4-bit case as an example, we have . Thus, the function can be defined as a mapping .The unsigned binary representation has the important property that every number between 0 and has a unique encoding as a -bit value. For example, there is only one representation of decimal value 11 as an unsigned 4-bit number— namely, . We highlight this as a mathematical principle, which we first state and then explain.Uniqueness of unsigned encoding
Function is a bijection
The mathematical term bijection refers to a function that goes two ways: it maps a value to a value where = , but it can also operate in reverse, since for every , there is a unique value such that . This is given by the inverse function , where, for our example, . The function maps each bit vector of length to a unique number between and , and it has an inverse, which we call (for “unsigned to binary”), that maps each number in the range to to a unique pattern of bits.]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.2-unsigned-encodings.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.2 Unsigned Encodings.md</guid><pubDate>Sat, 26 Jul 2025 01:54:30 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.2.1 Integral Data Types]]></title><description><![CDATA[C supports a variety of integral data types. Each type can specify a <a data-tooltip-position="top" aria-label="2.1.2 Data Sizes" data-href="2.1.2 Data Sizes" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.2-data-sizes.html" class="internal-link" target="_self" rel="noopener nofollow">data size</a> with keyword char, short, long, as well as an indication of whether the represented numbers are all nonnegative (declared as unsigned), or possibly negative (default).The number of bytes allocated for the different sizes varies according to whether the program is compiled for 32 or 64 bits. Based on the byte allocations, the different sizes allow different ranges of values to be represented. The only machine-dependent range indicated is for size designator long. Most 64-bit programs use an 8-byte representation, giving a much wider range of values than the 4-byte representation used with 32-bit programs.<br>
<img alt="Pasted image 20250725180054.png" src="assets/pasted-image-20250725180054.png" target="_self" style="width: 590px; max-width: 100%;">
Ranges are not symmetric—the range of negative numbers extends one further than the range of positive numbers.<br>
<img alt="Pasted image 20250725180109.png" src="assets/pasted-image-20250725180109.png" target="_self">]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.1-integral-data-types.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.1 Integral Data Types.md</guid><pubDate>Sat, 26 Jul 2025 00:01:31 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.2.0 Integer Representations]]></title><description><![CDATA[There are 2 ways bits can be used to encode integers, one that can only represent nonnegative numbers, and one that can represent negative, zero, and positive numbers.This list the mathematical terminology we introduce to precisely define and characterize how computers encode and operate on integer data.
<img alt="Pasted image 20250725174630.png" src="assets/pasted-image-20250725174630.png" target="_self">]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.2-integer-representations/2.2.0-integer-representations.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.2 Integer Representations/2.2.0 Integer Representations.md</guid><pubDate>Fri, 25 Jul 2025 23:46:36 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.1.9 Shift Operations in C]]></title><description><![CDATA[Shift operators shift bit patterns to the left and to the right.For an operand x having bit representation , the C expression x &lt;&lt; k yields a value with bit representation . That is, x is shifted k bits to the left, dropping off the k most significant bits and filling the right end with k zeros. The shift amount should be a value between 0 and w − 1. Shift operations associate from left to right, so x &lt;&lt; j &lt;&lt; k is equivalent to (x &lt;&lt; j) &lt;&lt; k.
Machines support two forms of right shift: A logical right shift fills the left end with zeros, giving a result . An arithmetic right shift fills the left end with repetitions of the most significant bit, giving a result . This convention is useful for operating on signed integer data.
<img alt="Pasted image 20250724145251.png" src="assets/pasted-image-20250724145251.png" target="_self">
Almost all computer/machine combinations use arithmetic right shifts for signed data, and many programmers assume this to be the case. For unsigned data, right shifts must be logical.
]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.9-shift-operations-in-c.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.9 Shift Operations in C.md</guid><pubDate>Thu, 24 Jul 2025 20:55:07 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.1.7 Bitwise operators]]></title><description><![CDATA[C supports <a data-tooltip-position="top" aria-label="2.1.6 Intro To Boolean Algebra" data-href="2.1.6 Intro To Boolean Algebra" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.6-intro-to-boolean-algebra.html" class="internal-link" target="_self" rel="noopener nofollow">boolean operations</a>. Boolean operators |, &amp;, ~, ^ can be applied to any "integral" data type.<br>
<img alt="Pasted image 20250722131129.png" src="assets/pasted-image-20250722131129.png" target="_self"><br>
The best way to determine the effect of a bit-level expression is to expand the <a data-tooltip-position="top" aria-label="2.1.1 Hexadecimal Notation" data-href="2.1.1 Hexadecimal Notation" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.1-hexadecimal-notation.html" class="internal-link" target="_self" rel="noopener nofollow">hexadecimal</a> arguments to their binary representations, perform the operation in binary, and then convert back to hex.A mask is a bit pattern that indicates a selected set of bits within a word.As an example, the mask 0xFF (having ones for the last significant 8 bits) indicates the low-order byte of a word. The bit-level operation &amp; yields a value consisting of the least significant byte of x, but with all other bytes set to 0. For example, with x = 0x89ABCDEF, the expression would yield 0x000000EF. The expression ~0 will yield a mask of all ones, regardless of the size of the data representation. The same mask can be written 0xFFFFFFFF when data type int is 32 bits, but it would not be as portable.The expression ~0xFF creates a mask where the 8 least-significant bits equal 0 and the rest equal 1. Observe that such a mask will be generated regardless of the word size. By contrast, the expression 0xFFFFFF00 would only work when data type int is 32 bits.]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.7-bitwise-operators.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.7 Bitwise operators.md</guid><pubDate>Thu, 24 Jul 2025 19:41:03 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.1.6 Intro To Boolean Algebra]]></title><description><![CDATA[See more on <a data-href="1.1.1 Boolean Algebra" href="boolean-logic/background/1.1.1-boolean-algebra.html" class="internal-link" target="_self" rel="noopener nofollow">1.1.1 Boolean Algebra</a><br>The simplest <a data-tooltip-position="top" aria-label="1.1.1 Boolean Algebra" data-href="1.1.1 Boolean Algebra" href="boolean-logic/background/1.1.1-boolean-algebra.html" class="internal-link" target="_self" rel="noopener nofollow">boolean algebra</a> is defined over the two-element set {0, 1}<br>
<img alt="Pasted image 20250720142153.png" src="assets/pasted-image-20250720142153.png" target="_self">
We can extend the four boolean operations to also operate on bit vectors, strings of zeros and ones of some fixed length . We define the operations over bit vectors according to their applications to the matching elements of the arguments.
Let and denote the bit vectors and , respectively. We define &amp; also be a bit vector of length , where the th element equals &amp; , for . The operations |, ^, and ~ are extended to bit vectors in a similar fashion.<br>
<img alt="Pasted image 20250722122228.png" src="assets/pasted-image-20250722122228.png" target="_self">One useful application of bit vectors is to represent finite sets. We can encode any subset with a bit vector , where = 1 if and only if .
For example, recalling that we write on the left and on the right, bit vector encodes the set , while bit vector encodes the set . With this way of encoding sets, Boolean operations | and &amp; correspond to set union and intersection, respectively, and ~ corresponds to set complement. Continuing our earlier example, the operation a &amp; b yields bit vector , while .]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.6-intro-to-boolean-algebra.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.6 Intro To Boolean Algebra.md</guid><pubDate>Tue, 22 Jul 2025 18:57:20 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.1.5 Representing Code]]></title><description><![CDATA[int sum(int x, int y)
{ return x + y;
}
When compiled on our sample machines, we generate machine code having the following byte representations:Linux 32 55 89 e5 8b 45 0c 03 45 08 c9 c3
Windows 55 89 e5 8b 45 0c 03 45 08 5d c3
Sun 81 c3 e0 08 90 02 00 09
Linux 64 55 48 89 e5 89 7d fc 89 75 f8 03 45 fc c9 c3Different machine types use different and incompatible instructions and encodings. Even identical <a data-tooltip-position="top" aria-label="CPU" data-href="CPU" href="cs_app/glossary/cpu.html" class="internal-link" target="_self" rel="noopener nofollow">processors</a> running different <a data-href="Operating System" href="cs_app/glossary/operating-system.html" class="internal-link" target="_self" rel="noopener nofollow">Operating System</a>s have differences in their coding conventions and hence are not binary compatible. Binary code is seldom portable across different combinations of machine and operating system.
A program, from the perspective of the machine, is simply a sequence of bytes. The machine has no information about the original source program, except perhaps some auxiliary tables maintained to aid in debugging.
]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.5-representing-code.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.5 Representing Code.md</guid><pubDate>Sun, 20 Jul 2025 20:15:17 GMT</pubDate></item><item><title><![CDATA[2.1.4 Representing Strings]]></title><description><![CDATA[A string in C is encoded by an array of characters terminated by the null (having value 0) character. Each character is represented by some standard encoding, with the most common being the ASCII character code.In a string "12345" and 6 (to include the terminating character), we get the result 31 32 33 34 35 00. This same result would be obtained on any system using ASCII as its character code, independent of the <a data-tooltip-position="top" aria-label="2.1.3 Addressing and Byte Ordering" data-href="2.1.3 Addressing and Byte Ordering" href="cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.3-addressing-and-byte-ordering.html" class="internal-link" target="_self" rel="noopener nofollow">byte ordering</a> and word size conventions. As a consequence, text data are more platform independent than binary data.]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.4-representing-strings.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.4 Representing Strings.md</guid><pubDate>Sun, 20 Jul 2025 18:48:26 GMT</pubDate></item><item><title><![CDATA[2.1.2 Data Sizes]]></title><description><![CDATA[Every computer has a word size, indicating the nominal size of pointer data. Since a virtual address is encoded by such a word, the most important system parameter determined by the word size is the maximum size of the <a data-tooltip-position="top" aria-label="virtual memory > Virtual Address Space" data-href="virtual memory#Virtual Address Space" href="cs_app/glossary/virtual-memory.html" class="internal-link" target="_self" rel="noopener nofollow">virtual address space</a>. That is, for a machine with a -bit word size, the virtual addresses can range from 0 to , giving the program access to at most bytes.A 32-bit word size limits the virtual address space to 4GB, that is, just over bytes. Scaling up to a 64-bit word size leads to a virtual address space of 16 exabytes, or around Most 64-bit machines can also run programs for 32-bit machines with
gcc -m32 prog.c
The C lang supports multiple data formats for both integer and floating-point data. The exact numbers of bytes for some data types depends on how the program is compiled.<br>
<img alt="Pasted image 20250716183124.png" src="assets/pasted-image-20250716183124.png" target="_self">
Integer data can be either signed, able to represent negative, zero, and positive values, or unsigned, only allowing nonnegative values. Data type char represents a single byte. Although the name char derives from the fact that it is used to store a single character in a text string, it can also be used to store integer values. Data types short, int, and long are intended to provide a range of sizesData types int32_t and int64_t have fixed data sizes regardless of compiler and machine settings. Using fixed-size integer types is the best way for programmers to have close control over data representations.Programmers should strive to make their programs portable across different machines and compilers. One aspect of portability is to make the program insensitive to the exact sizes of the different data types.]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.2-data-sizes.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.2 Data Sizes.md</guid><pubDate>Thu, 17 Jul 2025 01:23:52 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.1.1 Hexadecimal Notation]]></title><description><![CDATA[Hexadecimal (or simply "hex") uses digits "0" through "9" along with characters "A" to "F" to represent 16 possible values, written in hexadecimal , the value of a single byte can range from to .A single byte consists of 8 bits. In binary notation, its values range from to . When viewed as a decimal integer, its value ranges from to .
Neither notation is very convenient for describing bit patterns. Binary notation is too verbose, while with decimal notation it is tedious to convert to and from bit patterns.. Instead, we write bit patterns as base-16, or hexadecimal numbers
<img alt="Pasted image 20250716131144.png" src="assets/pasted-image-20250716131144.png" target="_self">
In C, numeric constants starting with 0x or 0X are interpreted as being in hexadecimal. The characters ‘A’ through ‘F’ may be written in either upper- or lowercase. For example, we could write the number FA1D37B16 as 0xFA1D37B, as 0xfa1d37b, or even mixing upper- and lowercase (e.g., 0xFa1D37b).When a value x is a power of 2, that is, x = 2n for some nonnegative integer n, we can readily write x in hexadecimal form by remembering that the binary representation of x is simply 1 followed by n zeros. The hexadecimal digit 0 represents 4 binary zeros. So, for n written in the form i + 4j , where 0 ≤ i ≤ 3, we can write x with a leading hex digit of 1 (i = 0), 2 (i = 1), 4 (i = 2), or 8 (i = 3), followed by j hexadecimal 0s. As an example, for x = 2,048 = 2 11, we have n = 11 = 3 + 4 . 2, giving hexadecimal representation 0x800.To convert a decimal number x to hexadecimal, we can repeatedly divide x by 16, giving a quotient q and a remainder r, such that x = q . 16 + r. We then use the hexadecimal digit representing r as the least significant digit and generate the remaining digits by repeating the process on q. As an example, consider the conversion of decimal 314,156: From this we can read off the hexadecimal representation as 0x4CB2C.Conversely, to convert a hexadecimal number to decimal, we can multiply each of the hexadecimal digits by the appropriate power of 16. For example, given the number 0x7AF, we compute its decimal equivalent as ]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.1-hexadecimal-notation.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.1 Hexadecimal Notation.md</guid><pubDate>Wed, 16 Jul 2025 21:45:31 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.1.0 Information Storage]]></title><description><![CDATA[Most computers use bytes (blocks of 8 bits), as the smallest addressable unit of memory. A machine-level program views memory as a very large array of bytes, referred to as <a data-href="virtual memory" href="cs_app/glossary/virtual-memory.html" class="internal-link" target="_self" rel="noopener nofollow">virtual memory</a>. Every byte of memory is identified by a unique number, known as its address, and the set of all possible addresses is known as the virtual address space.<br>
<img alt="Pasted image 20250715224120.png" src="assets/pasted-image-20250715224120.png" target="_self" style="width: 600px; max-width: 100%;"><br>
This virtual address space is just a conceptual image presented to the machine-level program. The actual implementation uses a combination of dynamic random access memory (DRAM), flash memory, disk storage, special hardware, and <a data-href="Operating System" href="cs_app/glossary/operating-system.html" class="internal-link" target="_self" rel="noopener nofollow">Operating System</a> software to provide the program with what appears to be a monolithic byte array<br>Various mechanisms are used to allocate and manage the storage for different parts of the program. This management is all performed within the virtual address space. For example, the value of a <a data-tooltip-position="top" aria-label="Pointers" data-href="Pointers" href="indexes/coding/c/pointers.html" class="internal-link" target="_self" rel="noopener nofollow">pointer</a> in C --whether it points to an integer, a structure, or some other program object-- is the virtual address of the first byte of some block storage. The C compiler also associates type information with each pointer, so that it can generate different machine-level code to access the value stored at the location designated by the pointer depending on the type of that value. Although the C compiler maintains this type information, the actual machine-level program it generates has no information about data types. It simply treats each program object as a block of bytes and the program itself as a sequence of bytes.]]></description><link>cs_app/ii.-representing-and-manipulating-information/2.1-information-storage/2.1.0-information-storage.html</link><guid isPermaLink="false">CS_APP/II. Representing and Manipulating Information/2.1 Information Storage/2.1.0 Information Storage.md</guid><pubDate>Wed, 16 Jul 2025 04:57:11 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item></channel></rss>